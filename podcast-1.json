{"podcast_details": {"podcast_title": "The AI Breakdown: Daily Artificial Intelligence News and Discussions", "episode_title": "Could AI End Up Being Good for Democracy?", "episode_image": "https://megaphone.imgix.net/podcasts/9ad36894-20f2-11ee-9d6c-d76aa9b66d23/image/BITCOIN_BUILDERS_3.png?ixlib=rails-4.3.1&max-w=3000&max-h=3000&fit=crop&auto=format,compress", "episode_transcript": " Today on the AI Breakdown, we're reading two pieces that argue that AI's impact on politics need not be as bad as everyone fears. The AI Breakdown is a daily podcast and video about the most important news and discussions in AI. Go to breakdown.network for more information about our Discord, our YouTube, and our newsletter. Hello friends, welcome back to the AI Breakdown. For this long read, we are actually doing a set of pieces, and they share a common theme. That common theme is the idea that artificial intelligence will have an impact on politics no matter what, but the extent to which it is positive or negative remains firmly in our control. The first piece is by Polly Curtis, CEO of the cross-party think tank Demos, and appeared first in The Guardian. The piece is titled, Artificial Intelligence is Powering Politics, but it Could Also Reboot Democracy. The YouTube clip I return to most often is David Bowie being interviewed by Jeremy Paxman on News 9 in 1999. Bowie is talking about what the internet might do. I don't even think we've seen the tip of the iceberg. I think the potential of what the internet is going to do to society, both good and bad, is unimaginable. I think we're on the cusp of something exhilarating and terrifying. It's just a tool, isn't it, condescends Paxman? It's an alien life form, insists Bowie. Is their life on Mars? Yes, and it's just landed here. At the time of that Bowie interview, I was writing a university dissertation titled Freedom of Speech in Cyberspace, the challenge the internet poses to the Constitution of the United States. It was a heady time, the peak of internet utopia, with tech idealists promising that the decentralizing nature of the internet would radically reform power dynamics and democracy could be reborn. Fast forward 25 odd years and we know the opposite has happened. Truth and trust have been eroded, democracy has failed to reform for the digital age, and the relationship between those in power and those who elect them is straining to the breaking point. It's at this moment that we are seeing the proliferation of generative AI, and understandably the response has been a mixture of hysteria and hope. The hysteria about killer robots risks masking the real societal impacts that industrial revolutions inevitably have, sifting winners and losers and disrupting ways of living in more subtle and sometimes pernicious ways. But there is hope for democracy in the AI revolution, if we put the right guardrails around it. If we make AI work for democracy, then in 10 years time our information ecosystems could be vastly improved to support democratic decision making. We could train AI to value verified information and serve it in ways that make the most complex information more accessible to more people. Politicians could be more trusted to do the right thing by people because they've learned new ways to involve people in decision making. AI citizens assemblies could help people and politicians to navigate through the tradeoffs required to tackle the big problems. These concepts are not entirely outlandish. Polis is one such tool developed in the US and used to shape policies most extensively in Taiwan, including to design regulation for Uber. Deceptively simple, Polis maps people's views according to consensus rather than division, and gives people options to suggest policy ideas. In the UK, we at Demos have worked with the Cabinet Office on Polis projects to engage experts and the public in the 2021 Integrated Review of Security, Defense, Development, and Foreign Policy. Andrew Gray, an independent candidate in July's Selby and Anstey by-election, is using it to power all his policies, declaring himself the first AI-powered politician. In a decade's time, we could repair the relationship between state and citizen. It could facilitate dialogue between MPs and constituents, enabling elements of direct democracy to supplement our representative system. AI could also allow for the better use of citizens' data to target public services, interventions, and support people on a more human level. AI could be used to guide people to access help from the state. But this will only happen if we make it happen. Because right now, the incentives to develop generative AI are all commercial, with investors steering the development of the technology in ways that threaten to further leave democracy behind, not least because the talent, expertise, and infrastructure follows the money, rather than aware it could be used for the common good. The Labour peer Jim Knight, who has been close to the latest digital bills going through Parliament, makes a startling point. There are four legislative processes regarding digital underway at the moment, if you include the AI white paper published earlier this year. None of them mention protecting or promoting democracy as an explicit aim. Instead, they are concerned with online safety, digital markets, and data protection. Democracy is the elephant in the room. Without focusing explicitly on the potential for AI to improve democracy, or at least do no harm, it will most probably corrupt. Distrusted information will proliferate, further eroding trust. But without explicitly updating our democracy to encompass more participatory activities that could be facilitated through these technologies, we will increasingly be left in a system that is centuries out of date, trying to govern in a world that moves to completely different speeds and in completely different ways. We have to learn this time. Alright, so clearly a UK view, and one that's not without concern, but that tries to put a pan on what's possible. Next up, we shift over to Russell Berman, a staff writer at The Atlantic. The piece is titled, Political Campaigns May Never Be The Same. How AI Could Save Politics If It Doesn't Destroy It First. Depending on whom you ask in politics, the sudden advances in artificial intelligence will either transform American democracy for the better or bring about its ruin. At the moment, the doomsayers are louder. Face impersonation technology and deepfake video are scaring campaign strategists who fear that their deployment in the days before the 2024 election could decide the winner. Even some AI developers are worried about what they've unleashed. The CEO of the company behind ChatGPT practically begged Congress to regulate his industry. Whether that was genuine civic-mindedness or self-serving performance remains to be seen. Amid the growing panic, however, a new generation of tech entrepreneurs is selling a more optimistic future for the merger of AI and politics. In their telling, the awesome automating power of AI has the potential to achieve in a few years what decades of attempted campaign finance reform have failed to do, dramatically reduce the cost of running for election in the United States. With AI's ability to handle a campaign's most mundane and time-consuming tasks\u2014think churning out press releases or identifying and targeting supporters\u2014candidates would have less need to hire high-priced consultants. The result could be a more open and accessible democracy, in which small, bare-bones campaigns can compete with well-funded juggernauts. Martin Courage, the founder of a Democratic fundraising company that is betting big on AI, calls the technology a great equalizer. He told me, You will see a lot more representation, because people who didn't have access to running for elected office will now have that. That in and of itself is huge. Courage told me that his firm, Sterling Data Company, has used AI to help more than 1,000 Democratic campaigns and committees, including the Democratic Congressional Campaign Committee and now Senator John Fetterman, identify potential donors. The speed with which AI can sort through donor files meant that Sterling was able to cut its prices last year by nearly half, Courage said, allowing even small campaigns to afford its services. Quote, I don't think there have ever been this many down-ballot candidates with some level of digital fundraising operation, Courage said. These candidates now have access to a proper campaign infrastructure. Campaigns big and small have begun using generative AI software such as ChatGPT and Dali to create digital ads, proofread, and even write press releases and fundraising pitches. A handful of consultants told me they were mostly just experimenting with AI, but Courage said that its influence is more pervasive. Almost half of the first drafts of fundraising emails are being produced by ChatGPT, he claimed. Not many campaigns will publicly admit it. The adoption of AI may not be such welcome news, however, for voters who are already sick of being bombarded with ads, canned emails, and fundraising requests during election season. Advertising will become even more hyper-targeted. Tom Newhouse, a GOP strategist, told me, because campaigns can use AI to sort through voter data, run performance tests, and then create dozens of highly specific ads with far fewer staff. ChatGPT said could narrow the gap between small campaigns and their richer rivals. But several political consultants I spoke with were skeptical that the technology would democratize campaigning anytime soon. For one, AI won't aid only the scrappy, underfunded campaigns. Deeper-pocketed organizations could use it to expand their capacity exponentially, whether to test and quick-produce hundreds of highly specific ads or pinpoint their canvassing efforts in ways that widen their advantage. Amanda Lippmann, the founder of Run for Something, an organization that recruits first-time progressive candidates, told me that the office seekers she works with aren't focused on AI. Hyperlocal races are still won by the candidates who knock on the most doors, robots haven't taken up that task, and even if they could, who would want them to? Lippmann said, the most important thing for a candidate is the relationship with the voter. AI can't replicate that, at least not yet. Although campaigns have started using AI, its impact even to people in politics is not always apparent. Federman's Pennsylvania campaign worked with Courage's AI First firm, but two former advisors to Federman scoffed at the suggestion that the technology contributed meaningfully to his victory. I don't remember anyone using AI for anything on that campaign. Kenneth Pennington, a digital consultant and one of the Federman campaign's earliest hires told me, Pennington is a partner at a progressive consulting firm called Middleseat, which he said had not adopted the use of generative AI in any significant way and had no immediate plans to. Part of what our approach and selling point is as a team and as a firm is authenticity and creativity, which I think is not a strong suit of a tool like ChatGPT, Pennington said. It's robotic. I don't think it's ready for primetime in politics. If AI optimists and pessimists agree on anything, it's that the technology will allow more people to participate in the political process. Whether that's a good thing is another question. Just as AI platforms could allow, say, a schoolteacher running for city council to draft press releases in between grading papers, so too can they help a far-right activist with millions of followers create a semi-believable deepfake video of President Joe Biden announcing a military draft. Hany Farid, a digital forensics expert at UC Berkeley told me, we've democratized access to the ability to create sophisticated fakes. Fears over deepfakes have escalated in the past month. In response to Biden's formal declaration of his re-election bid, the Republican National Committee released a video that used AI-generated images to depict a dystopian future. Within days, Democratic Representative Yvette Clark of New York introduced legislation to require political ads to disclose any use of generative AI, which the RNC ad did. Earlier this month, the bipartisan American Association of Political Consultants issued a statement condemning the use of deepfake generative AI content as a violation of its code of ethics. Nearly everyone I interviewed for this story expressed some degree of concern over the role that deepfakes could play in the 2024 election. One scenario that came up repeatedly was the possibility that a compelling deepfake could be released on the eve of the election, leaving too little time for it to be widely debunked. Clark told me she worried specifically about a bad actor suppressing the vote by releasing invented audio or video of a trusted voice in a particular community announcing a change or closure of polling sites. But the true nightmare scenario is what Farid called death by a thousand cuts, a slow bleed of deepfakes that destroys trust in authentic soundbites and videos. If we enter this world where anything could be fake, you can deny reality. Nothing has to be real, Farid said. This alarm extends well beyond politics. A consortium of media and tech companies are advocating for a global set of standards for the use of AI, including efforts to authenticate images and videos as well as to identify, through watermarks or other digital fingerprints, content that has been generated or manipulated by AI. The group is led by Adobe, whose Photoshop helped introduce the widespread use of computer image editing. We believe that this is an existential threat to democracy if we don't solve the deepfake problem, Dana Rao, Adobe's general counsel, told me. If people don't have a way to believe the truth, we're not going to be able to decide policy, laws, government issues. Not everyone is so concerned. As vice president of the American Association of Political Consultants, Larry Hune helped draft the statement that the organization put out denouncing deepfakes and warning its members against using them. But he's relatively untroubled by the threats they pose. Frankly, in my experience, it's harder than everyone thinks it is, says Hune, whose day job is providing digital strategy to Democratic clients who include Senate Majority Leader Chuck Schumer. Am I afraid of it? No, he told me. Does it concern me that there are always going to be bad actors doing bad things? That's just life. Betsy Hoover, a former Obama campaign organizer who now runs a venture capital fund that invests in campaign tech, argued that voters are more discerning than people give them credit for. In her view, decades of steadily more sophisticated disinformation campaigns have conditioned the electorate to question what they see on the Internet. Voters have had to decide what to listen to and where to get their information for a really long time, she told me. And at the end of the day, for the most part, they figured it out. Deepfake videos are sure to get more convincing, but for the time being, many are pretty easy to spot. Those that impersonate Biden, for example, do a decent job of capturing his voice and appearance, but they make him sound slightly, well, younger than he is. His speech is smoother, without the verbal stumbles and stuttering that have become more pronounced in recent years. The technology, quote, does require someone with real skill to make use of, he said. You can give me a football, I still can't throw it 50 yards. The same limitations apply to AI's potential for revolutionizing campaigns, as anyone who's played around with chat GPT can attest. When I asked chat GPT to write a press release from the Trump campaign announcing a hypothetical endorsement from the former president by his current Republican rival, Nikki Haley, within seconds, the bot delivered a serviceable first draft that accurately captured the format of a press release and made up believable, if generic, quotes from Trump and Haley. But it omitted key background information that any junior level staffer would have known to include. That Haley was the governor of South Carolina, for example, and then served as Trump's ambassador to the United Nations. Still, anyone confident enough to predict AI's impact on an election nearly a year and a half away is making a risky bet. Chat GPT didn't even exist six months ago. Uncertainty pervaded my conversations with the technology's boosters and skeptics alike. Pennington told me to take everything he said about AI, both its promise and peril, with a grain of salt because he could be proved wrong. Hoover said, I think some people are overhyping it. I think some people are not thinking about it who should be. There's a really wide spectrum because all of this is just evolving so much day to day. That constant and rapid evolution is what sets AI apart from other technologies that have been touted as democratic disruptors. Karrouge said, this is one of the few technologies in the history of planet Earth that is continuously and exponentially bettering itself. End quote. Of all of the predictions I heard about AI's impact on campaigns, his were the most assured. Because AI forms the basis of his sales pitch to clients, perhaps his prognostication too should be taken with a grain of salt. Although he was unsure exactly how fast AI could transform campaigns, he was certain it would. You no longer need average people and average consultants and average anything, Karrouge said, because AI can do average. He compared this skeptics in his field to executives at Blockbuster who passed on the chance to buy Netflix before the startup eventually destroyed the video rental giant. The old guard, Karrouge concluded, is just not ready to be replaced. Hoover offered no such bravado, but she said Democrats in particular shouldn't let their fears of AI stop them from trying to harness its potential. The genie is out of the bottle, she said. We have a choice then as campaigners to take the good from it and allow it to make our work better and more effective, or to hide under a rock and pretend it's not here because we're afraid of it. I don't think we can afford to do the latter. Alright guys, back to NLW here for a really quick wrap up. So on the one hand, this is a pretty standard format at this point for discussion of AI, right? On the one hand, there's a lot of possibility. On the other hand, there's a lot of challenge. At the same time, there are two reasons that I thought these were interesting to share. The first is that it's about an area that I think is going to come up a lot more as the election season rolls on, which is of course politics. And second, because the air and tone around each of these pieces is to look for that optimistic take when so much of the discourse right now is around deepfakes and the threat to democracy. Now what's interesting is you might have found yourself in each example shaking your head yes you agreed or shaking your head no you didn't agree about where the transformation might lie. Will AI make campaigning easier, thus meaning more people can do it? Or will the advantage accrue to those who have money still so much more that AI allows them to get farther ahead? There are great debates to be had about that exact question, but at least they're starting from the possibility that it could be a good thing. So much of the political discourse around this topic when it comes to politics is negative a priori that I found the tone refreshing. Now when it comes to what I think, the honest answer is I'm not totally sure yet. Where I found myself agreeing most vociferously with the biggest head nods was with the argument of the person who said that voters are more discerning than we give them credit for. I've said some version of this before numerous times on this show, but the biggest reason my P-Doom is lower than some of my AI safety peers is because I just don't think we're going to end up sleepwalking into self-destruction. And when it comes to this election cycle, my firm expectation is that there is going to be so much discourse about the risk of deepfakes and the rise of deepfakes that everyone is going to be on hyper alert for deepfakes. We're going to develop a collective immune system that we don't have right now to political deepfakes simply by virtue of having to go through it and by knowing that it's a real risk. Now I don't want to say that that doesn't mean that they're not still a risk. I especially think really simple subtle things like a voice clone of a community leader saying a polling place has changed could be really disruptive. I'm less concerned with some big crazy conspiracy like Biden starting a draft because I think people are just going to be extremely wary of that type of misinformation. But who knows? All I know is that we'll have a heck of a lot more information about how scared of these things to be after the next election cycle. So all we can do is keep living through it. Thanks as always for listening or watching. Until next time, peace."}, "podcast_summary": "In today's podcast episode, two articles are discussed that argue that AI's impact on politics can be positive rather than negative. The first piece, by Polly Curtis, suggests that if AI is used appropriately, it could potentially improve democratic decision-making and information accessibility. The article highlights tools like Polis, which maps people's views and encourages consensus-based decision-making. The second piece, by Russell Berman, focuses on the potential of AI to reduce the cost of running political campaigns and make the democratic process more accessible. However, concerns about deepfakes and their impact on elections are also raised. Both articles express differing opinions on the potential of AI in politics, but emphasize the need for careful and responsible implementation to ensure positive outcomes.", "podcast_guest": "Kony 2012 is a 2012 American short documentary film produced by Invisible Children, Inc. The film's purpose was to make Ugandan cult leader, war criminal, and ICC fugitive Joseph Kony globally known so as to have him arrested by the end of 2012. The film was released on March 5, 2012, and spread virally, and the campaign was initially supported by various celebrities.As of April 5, 2023, the film had received over 103 million views and 1.3 million likes on the video-sharing website YouTube, and over 18.7 million views and over 21.8 thousand likes on Vimeo, with other views on a central Kony 2012 website operated by Invisible Children. At the time, the video was the most liked on the whole of YouTube, and is the first video ever to reach 1 million likes. The intense exposure of the video caused the Kony 2012 website to crash shortly after it began gaining widespread popularity. A poll suggested that more than half of young adult Americans heard about Kony 2012 in the days following the video's release. It was included among the top international events of 2012 by PBS and called the most viral video ever by TIME in 2013.The campaign resulted in a resolution by the United States Senate and contributed to the decision to send troops by the African Union. The film also called for an April 20 worldwide canvassing campaign, called \"Cover the Night\". On April 5, 2012, Invisible Children released a follow-up video, titled Kony 2012: Part II \u2013 Beyond Famous, which failed to repeat the success of the original.", "podcast_highlights": "- The first piece argues that AI could have a positive impact on democracy if the right guardrails are put in place.\n- AI could help improve information ecosystems, involve people in decision making, and facilitate dialogue between politicians and constituents.\n- The development of AI is currently driven by commercial incentives, threatening democracy.\n- Legislative processes regarding digital technology do not explicitly mention protecting or promoting democracy.\n- The incentives to develop generative AI are focused on commercial gain rather than the common good.\n- The second piece discusses how AI could potentially reduce the cost of running for election by automating mundane tasks and making campaigns more accessible.\n- AI software like ChatGPT and Dali can be used to create digital ads, proofread, and write press releases and fundraising pitches.\n- There are concerns about the hyper-targeted advertising enabled by AI and the potential for the spread of deepfake videos.\n- AI has the potential to democratize campaigns, but there are doubts about whether it will truly level the playing field.\n- Voters are seen as being more discerning than people give them credit for, but deepfakes are still a significant concern for the 2024 election.\n- There are ongoing debates about the impact of AI on campaigns, but the technology is continuously evolving."}