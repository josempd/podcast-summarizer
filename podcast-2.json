{"podcast_details": {"podcast_title": "Technically Optimistic", "episode_title": "Bishop Paul Tighe on AI and our humanity", "episode_image": "https://f.prxu.org/3954/images/a23de8dc-dd05-4544-829e-70188b9f26bf/EP_Cover_Technically_Optimistic_2023.06.02_v2.jpg", "episode_transcript": " There's an old Irish definition of education. You've gone from a cocksure ignorance to thoughtful uncertainty. I think thoughtful uncertainty is actually a useful thing. It's that we reflect and think even if we don't have the best of answers. We shouldn't feel pressured to have the best of answers and everything else. I feel if I were to rename my podcast, I would rename it from technically optimistic to thoughtful uncertainty. That's really great. Hey, it's Rafi Krikorian and this is Technically Optimistic. We just finished our first season, which was all about AI. And over the course of those six episodes, we get into the big, complex and nuanced questions raised by artificial intelligence. We didn't want to simply focus on AI hype or the AI doom. Instead, we wanted to hear from all kinds of voices like tech experts like Tristan Harris, Meredith Broussard, Roz Picard, sitting US lawmakers like Senator Michael Bennett and Representative Jay Obernolte. But we also spoke to people that don't usually get quite as much airtime, like the Brooklyn-based artist Adi Melenciano or the Hawaiian geneticist, Keolu Fox. Not to mention a personal hero of mine, the Nobel Peace Prize winning journalist, Maria Ressa. We want you to hear from many different voices with a variety of different perspectives so you can form your own opinions. There's an episode specifically about AI and education, as well as a two parter about the massive challenges of AI regulation. But it all starts with episode one. It's called AI is at a Crossroads. How do we get here? You'll hear from Pulitzer Prize winning journalist John Markoff and others. We tell the recent but little known history of AI and talk about the big, not so obvious questions this technology raises. If you haven't heard this episode or the whole season, you're going to want to check it out. I had so many interesting conversations and they didn't all make it into the six episodes. So over the next few weeks, I'm happy to be sharing a few bonus episodes. You're going to hear extended discussions with some of the sharp voices we featured and some new voices you haven't heard from yet. Like today's episode featuring my talk with Bishop Paul Tai. Paul works in Rome in the administration of the Catholic Church as the Vatican's Secretary of Culture. The point of his job is to engage in dialogue with all sorts of people about all facets of human life today. And he's been particularly interested in artificial intelligence. Turns out so has his boss, Pope Francis. The Pope acknowledged the potential benefit that artificial intelligence can have on humanity. And he also emphasized the importance of using technology both ethically and responsibly. I love this particular conversation with Paul. He is so thoughtful and so nuanced. And obviously he's a representative of the Catholic Church. But as you'll hear, his main interest is humanity and preserving what makes us human. Humanity is something, in my opinion, that transcends any particular faith, religion, or institution. And hey listeners, we would love to hear from you. Send us an email with your thoughts, feedback, questions, anything. Write to technicallyoptimistic at emersoncollective.com. Visit us on the web at emersoncollective.com slash technically dash optimistic dash podcast. And follow us on social media at Emerson Collective. Pretty soon we'll have more to tell you about season two, which is coming soon. But for now, enjoy my conversation with Bishop Paul Ty. So maybe to start us off, Paul, can you tell me a little bit about the role you're currently in at the Vatican? How'd you wind up there? Well, it's a kind of a complicated story that reflects my own training. Way back I studied law as a student in Ireland, civil law. Subsequently I studied theology with a lot of interest in ethical issues. And the interface of law and morality was always something I was interested in. The interface of law, ethics, public policy, a kind of an issue that I was interested in, was teaching in. And then also I was involved in working in communications in Dublin at the Diocese in Dublin. I was sent to Rome about 15 years ago. I was asked to come to Rome and to work on communications here in Rome. And my interest at the time became on digital communications, because that was really just taking off at that time about 15 years ago. And part of my interest really then developed into not just digitalization and its impact on communications and communications technology, but what it was doing to our cultures, to how we form communication, to how we communicate with each other, how we have in many ways had to rethink so many of our categories of life. And that probably led me inevitably into an interest in other technological developments such as AI, which also have the potential looking towards the future to impact very much how we think of ourselves as human, how we function as a society, and how we as individuals either prosper or don't prosper. Having worked in communications for seven, eight years, I was moved to the Vascals Department for Culture, which is a department which has also had a huge interest in dialogue with the world beyond the church and beyond the areas of faith. How do we dialogue with people who don't necessarily come from a religious background or present as people with religious belief, but who obviously are equally interested in quantities that make society prosper and make our world prosper? So the juxtaposition of my interest in digitalization, digital culture, and this interest that I have in dialogue with people who come from outside our own faith tradition, I think probably led to a lot of my involvement in this area. That's amazing. What was the spark that caught your eye, the church's eye, the pope's eye, around AI specifically? Is there a particular theme that makes you interested in it and feel that you need to be part of that conversation? Yeah, I think our awareness of the emergence of AI and the Syrians issue probably goes back six or seven years ago. And really that was some people from the Valley who came to Rome who asked to have a dialogue with people from around the Vatican and said, you know, we're alert to something that's coming down the road. We're alert to the developments that are happening in AI, machine learning, and deeper forms of more autonomous AI. And we think you should be thinking about them because they're going to have at a minimum a huge impact socially on society, but also because we think they're making us ask questions about what it is that makes us human, about what it is that distinguishes us as human beings. And increasingly, they were probably saying many of the things that we would have said, well, these are things that only humans are doing. We may find machines capable of doing. So what is it that is distinctively human? And how do we ensure that the emergence of new technologies don't in any way restrict or impede our basic humanity? One of the issues that I think will probably be very important for us there is that as human beings, it's our capacity to relate to each other, to be in solidarity with each other, to respect each other as different but autonomous, and also our human ability to think, reflect, to take time about issues. How do we keep that alive and not feel that we have to respond to everything at the speed of the machine? I mean, that's such an interesting way to phrase it. One of the things I've been talking to a lot of people about is the question of values, especially as this technology is being created. In some ways, you can make the argument that power is shifting in our society. Power used to rest with, and still does with, kings and politicians. It moved to people with wealth, and now it might be moving to the people who are deploying these technologies, the people who are casting this technology upon us in some way. I'm curious both your perspective on the people who are building this technology, but also the lessons that we should be taking as we're sort of watching this roll out onto our society. Yeah. I mean, I think there's some very immediate issues that I think is probably of a concern, and Pope Francis has spoken about this, is a concern about increased inequality. I mean, we can't deny that in general terms, technology has helped us to overcome many forms of poverty, but at the same time, we're seeing an increase in the disparity between the extraordinary wealth, the minorities, the people who own and who are developing the new technologies, and the rest of humanity. Very often, as we look at the future of the earth, with the positive energy that some of the middle classes could even more squeeze than they are at the moment, there's a material element to it, yes, the distinction between those who have and have an extraordinary abundance of kind of magical figures of wealth and those who don't have. Parallel to that, there's an increase in inequality in terms of access to power. Who determines who will be elected? Who determines how governments will deal with the issues which are of interest to some of those minorities? And one which I think is not unfair to say, it's even a question about, is there a fracturing of the sense of human destiny? Some of the people who have made extraordinary sums of money and who have created very worthwhile technologies are increasingly interested in visions about the future of humanity and space travel, which have their own value, but are not necessarily rooted in a sense of the solidarity of all people. They're not necessarily addressing the more basic questions about poverty, about migration, dealing with some of the simple illnesses that are killing so many people in our world. And it's also who decides where all this money, I mean, the United States, particularly in that sector, there's a very noble tradition of philanthropy, but it's not a philanthropy that necessarily is subjected to democratic oversight. So loss of inclusivity, loss of a sense of when we think about how are these technologies going to impact humanity? How are they going to change our future? How are they going to shape the world your children may live in? Who gets to be part of that conversation and who gets to be in the decision making? I mean, that's really one of the core questions, I believe. If you believe the idea that we should be doing some of this work for the public good, for the good of all of us, how do we define what is that good? I was struck by an article I read about two or three years ago, maybe more, but two or three years ago, it was my guess, by Kissinger, Henry Kissinger, in which he spoke about one of the things that was positive about all the people who were working the area of AI, that they wanted to be at the service of humanity, they wanted to be for human good, they wanted to be person-centered. And he said, that is noble, but he also made the point that disputing what that means, there's 2000 years of history to how we make determinations about what's good, of what is truly going to promote human well-being and all. I think the other challenge from an ethical perspective is we're having to address these issues globally, taking account of different religious traditions, different national traditions, different cultures. And one of the things that Pope Francis is trying to make a point is he's trying to determine what is the human good, what are the values that actually promote human flourishing, but enable people to live well as individuals and to live well together in society. That is a commitment to searching together for the truth of that. We don't necessarily have all the right answers that help them easily to hand, but we believe that there is a possibility of making determinations of what are the values that will promote better societies, that will promote the dignity of all human beings, that will promote justice among people. We may not be able to develop hugely deep consensus about that, but we may well be able to identify the things that certainly damage that. And anything that goes against human dignity, that makes it another person, a means to an end and not a person of value, even him or herself, is something to be avoided. Anything that fractures our capacity to relate to each other, to converse with each other, to understand each other is something that is very dangerous, helps our preoccupation and worries about fake news. All of those things are wrong because they're going to destroy our ability to flourish as human beings and to live in harmony with each other in society. So if you subscribe to a world that says, look, it's everyone for themselves, let's get out there and fight for ourselves and use this technology for our own ends. I think we have to acknowledge that that mentality is one that would destroy our humanity, would destroy our capacity to live together. So I'm a bit worried that we're already living in that world. Like a lot of these technologies are already being developed within a system that incentivizes money. And so people race to deploy them as quickly as possible. They're less careful about safety standards and data protections and so on. So if we're already living in this everyone for themselves kind of world, how do we get out of it? Well, I think, I think part of it is first of all, recognizing it. If I think of Pope Francis again in addressing technology, he obviously celebrates the goodness of technology, but also would want to recognize that technology on its own is not going to make our world a better place. There's a need for human agency in that. One point he has brought out very strongly is not just a question of technology being neutral, it can be used for good or could you use it for bad. And we just need to keep it out of the hands of bad actors or we all make commitments to using it properly. He also recognized that technology is born, what he calls a technocratic environment. But the technology is produced by companies or individuals that already have certain values. A lot of our technology today is being developed by commercial companies who are driven by profit motives, who are responding to shareholders who are making certain demands of them. And we have to ask if that environment is necessarily going to be conducive to taking the time of careful ethical decision-making we need before developing and deploying technologies that have a potential to transform us in ways that we haven't fully understood. So that's really, I think, a question about looking beyond the goodwill, badwill of any individual and looking at the systems which are producing them. I'm asking questions about whether those systems, do we need to rethink systemically what we're doing? I mean, there are very many admirable things about Silicon Valley and the culture of Silicon Valley and the culture of technology. The whole idea of disruption, which can be okay if I'm disrupting an economic model to produce an economic model or a way of production that would be more effective, that's fine. But if ultimately I'm running a risk of disrupting patterns of human living that helps promote human wellbeing, then I think it's a different issue. And I think there's that need to think more, not just individually, and not just to think about our own media peer group, but to think about the impact on a broader section of society and the impacts of that. I mean, I've been struck very strongly by some of the articles I've been reading about the gig economy, where the gig economy can promise so many things. When you learn about the lifestyle of people who are at the lower end of the food chain trying to meet deadlines imposed by algorithms, that any turn them into machines and they will be replaced by machines today, the machines are more effective. But secondly, take no account of their humanity, but also turn everybody into competitors who can do this more quickly, more fast. We have to ask about what that is doing to break down the basic dignity of individuals and the solidarity of society. We'll be right back after a quick break. One of the things I think I heard you say is these incentive models that are causing people to behave are actually maybe the root of the issue. And then we need to go and make a direct attempt to change those incentive models so that we can remind ourselves what it is to be human as opposed to simply just optimizing ourselves. Yeah. No, I think education has a huge role in this. We can take our own responsibility for the kind of material that we're reading and the views on expressing. But I think we also need to be alert to that there are algorithms there that are reinforcing our biases. There are algorithms there that are helping us to associate with others who seem to share our views and tell us how great we are and how wrong the other people are. Because people want stickiness on their platforms. One of the ways to keep people on their platform is feeding them what they like immediately, whether it's what they really need or not is a toleration. There is a role for regulation and there has to be a role for regulation because there is a role for better ethics by the companies. But there's also, I think, an awareness of, and certainly my point, a need to help people to be more intentional and more mindful in how they engage with the technologies. To be more intentional means being alert to how the rules of the game play out, how I may find myself trapped in an echo chamber reinforcing my biases, how I may have to make a deliberate intention of choice to engage with materials which may be outside my comfort zone but alert me to a different way of seeing things. I think that is important. Attentiveness to probably the most precious commodity I have, my time, my attention, where is my attention going? I need to be more alert to and engaged with that. As we move into the future of AI, I think the values are there, but it's about thinking how we actually embed those values or take responsibility for those values in different corporate and institutional sessions. May I ask, is it unusual for the church to be trying to be in front of these issues as opposed to reacting to these issues? But I mean, I'm not sure to what extent you could say we are in front. It's a reactive element. Life moves and you're trying to think and reflect and respond. But I would say that there's an effort here to give us a lot of time and reflection precisely because it's hitting issues that are at the core of our technology and of our identity of what it is to be human. And I think particularly a risk that somehow we lose the sense of the fundamental dignity value and worth of every human person. The capacity of human people to grow and to develop. Even the more pragmatic, immediate things of the future of work. Okay, the technology is saying, well, no technology, even the short-term cause a problem with loss of work, but in the long-term, it has always generated more work or different forms of work. I would like to be optimistic about that. But what we're seeing is maybe a devaluing of a lot of work. We're looking at people looking at solutions which are again, very well intentioned about what there won't necessarily be the same need for people to work. We will think about the universal social benefit that we can give all people universal income. But work isn't just about earning our living. It's not just about acquiring material things. It's into work. We express our creativity. It's often into work, certainly prependent, that we socialize. We form community and we form identity. So I think these types of issues for me remain very important and for the church. A lot of our algorithms are working on predictions based on past performance. So we're determinations of social welfare entitlements, determinations of parole hearings, are what we very much usage on in analysis. And one can see from a logical perspective why that makes sense because very often it is past performance that indicates how people are likely to behave in the future. But we'd like to believe that people can change, can change for the better. People can grow. People can change in very real ways. Deeply talk about the language of conversion of people changing. Will there be room left for people to change? Will a judge ever be willing to take a chance on extending mercy to somebody if he or she is afraid that they'll be held to account because the honor of the rhythm would have suggested a harder line. I'm curious then, like, what do we need to be educating or teaching these engineers, these creators, the people who are working these systems? What else should they be learning in order to have this broader view? Yeah, this looks interesting. I was at a European Union meeting about ethics. The German ethics council were basically saying everybody should get a strong input from the humanities in their education. Everybody is quite strongly, if I can understand, advocating for STEM and the importance of STEM. And STEM is very important. But at the same time, we have to be able to engage with the broader types of humanities that get us reflecting on what it is that makes us human, what it is that really makes life worthwhile, what it is that gives us a sense of identity and shared communion with other people. And that, I think, is partly true of humanities. And maybe another thing that I know many Catholic universities do of that, and I think is very important, is that they insist on everybody studying the humanities as part of their special report, their day, that they have some level of humanities input. But also, I think, very often they expose people to social action, social justice, meeting with and working with people who are different from them so that they don't just stay in a bubble. They realize a broader understanding of life and what it is that makes life worthwhile. So certainly for me, I think it's about enabling people to meet with, to encounter, to learn from, and to grow an appreciation of those who are different from them. I would be curious to your reaction to people who would say, well, that's highly inefficient. Our society is highly inefficient. Shouldn't we be working to make it more efficient in some ways? Yeah. I mean, I think efficiency is a thing. And I can understand. I've been reading a little bit. I can't blame to be an expert on effect of altruism, which is kind of trying to say, let's be more rational. Let's think through what are the things you can do with your life that will make this world a better place. Okay. And rather than you going off and training as a doctor and going off to Africa and maybe saving 140 lives in your lifetime, go and be a venture capitalist, made lots of money. And that money then you can send to Africa. You just do more money than you as a doctor. There is a kind of an efficiency thing there. And it's rational. It's seemingly scientific. But what it bypasses is who are you in the midst of this? Our actions are not just things we perform in a world to have consequences. Our actions become expressions of who we are and how we relate to other people and what our values are. So I think a ruthless focus on efficiency bypasses the question towards what do we want to be efficient? Do we want to be more commercially viable? Do we want to be more, our technologies to be faster, to be smaller, to be more diffused? And yeah, I can measure that. So my worry a little bit about AI is that it's in the area of measurement. And I'm not sure that all the most important human values and the things that make our life worthwhile are things that we can measure. I'm curious then what you're excited about in this space. I mean, there's so much out there. So like, I'm just curious what would be a thing that catches your eye? I mean, I can't, I think we have to step back every now and again and recognize and celebrate some of the extraordinary achievements of this, okay? You and I are now speaking at quite a distance from each other to a technology that is relatively, and it's allowing a type of conversation. And I think what we have to do is, my hope in this area, I've always tried to avoid the area of condemning and saying what's wrong and try and see what is the real potential of some of the technologies that are emerging. Where can they really make a difference? And how do we ensure that those potentials are realized? Just this morning, I was listening to something on BBC and they're talking about Addenberg's big hospital in Oxford, working together with Microsoft on new forms of analysis of X-rays and the AI being able to process so much more information that can allow for much more accurate diagnostics, which is something that then theoretically has the potential to liberate the doctor, the nurse, to be more attentive to the patient. I'm also conscious that other critics have written the real risk in our world is if that technology develops, it's just no, the doctor will now be expected to see more patients and process more people in the name of efficiency. Whereas the type of efficiency that is there in a doctor listening, being sympathetic, being understanding, being attentive, being present to his or her patient are the values that I think technology will allow us to cultivate if it's properly freed from some of the biases that inhabit our world. I mean, it's almost sort of miraculous, the first draft that the CHAP GP team can produce on some issue or some topic gets a lot of stuff done very quickly. Now I need the human judgment to know is it right? Is it wrong? Has it taken account of all the factors? Could some of the inputs that are in there be skewed already? I think focusing on what it is as humans we have in terms of judgment making and analysis and census of solidarism to ensure that those shape the applications of technologies. There are certain values in life, the value of love, the value of forgiveness, the value of tenderness, the value of reconciliation that you can't measure, but are ultimately so many ways more transformative of our world than those things that maybe we can't measure. You mentioned before creativity and you know, creativity in some ways a lot of people would say is the domain of humans. What does it mean for us when these systems start seeming to be creative? How does our relationship with that word change? It's an interesting thing. I mean, I was pretty much at the beginning of time saying, look, these things can never be creative. They can play around with so we can give them so much music and ask them to make some new music and that new music, that's I think a derived form of creativity. It can synthesize, it can put together, it can combine, but can it bring something new into that? Not necessarily, but then again, most of us probably don't have those levels of creativity ourselves in our lives. Okay. True. So one argument that I've been kind of struck by is that those who are truly creative will probably be able to be even more creative using the technologies that will speak to the processes, but I think that the injection of that which is new, which is unprecedented, which takes us into a new domain, I think is where the true creativity emerges. Paul, thank you so much for, you've literally given me so much to think about. I think I'll be thinking about this for the rest of the day. Go ahead. Paul Tai, thank you so much for talking with me today. You're welcome. Stay subscribed to Technically Optimistic. We've got more bonus episodes coming in the next few weeks, and I think you're going to be really excited by some of the guests you'll hear from. Our email address is technicallyoptimistic at emersoncollective.com and follow us on social media at Emerson Collective. I'm Rafiq Rakhourian. Thanks so much for listening and see you next time on Technically Optimistic."}, "podcast_summary": "In this podcast episode, Rafiq Krikorian reflects on the first season of his podcast, \"Technically Optimistic,\" which focused on artificial intelligence (AI). He highlights that the podcast aimed to explore the complex questions raised by AI without falling into the hype or doom narratives surrounding it. Krikorian interviewed a variety of voices, including tech experts, lawmakers, artists, and geneticists, to provide different perspectives on AI's impact. He also mentions upcoming bonus episodes that will feature extended discussions with some of the guests from the first season. In this particular episode, Krikorian speaks with Bishop Paul Tai, the Vatican's Secretary of Culture, about the ethical considerations of AI and the need to preserve humanity and human values in the face of technological advancements. They discuss issues such as inequality, power dynamics, measurement, and the role of education in shaping the engineers and creators of AI. Krikorian concludes the episode by inviting listeners to share their thoughts and feedback, and he hints at the upcoming second season of the podcast.", "podcast_guest": "Ty Hubert Detmer (born October 30, 1967) is an American former professional football player who was a quarterback in the National Football League (NFL). He won the Heisman Trophy in 1990 while playing college football for the BYU Cougars. Detmer broke numerous NCAA records with BYU, and was twice recognized as a consensus All-American. A late-round pick in the 1992 NFL Draft, Detmer played for six NFL teams over 14 seasons, mostly in a back-up role.\nAfter his playing career, Detmer became a coach. He was the offensive coordinator at BYU from 2015 to 2017. He is the older brother of former NFL quarterback Koy Detmer.", "podcast_highlights": "Highlights from the podcast episode with Bishop Paul Tai include:\n\n- The discussion about the emergence and potential impact of artificial intelligence (AI) on society.\n- The importance of using technology ethically and responsibly.\n- The need to reflect on what it means to be human and preserve our basic humanity in the face of advancing technology.\n- The role of power and decision-making in the development and deployment of AI.\n- The implications of AI for inequality, access to power, and the fracture of human destiny.\n- The value of dialogue, inclusivity, and solidarity in shaping the future of AI.\n- The need for education that includes a humanities perspective and exposure to different viewpoints.\n- The danger of a focus on efficiency without considering the broader values and implications.\n- The potential benefits of AI, such as improved diagnostics in healthcare, but also the importance of maintaining human judgment and values in decision-making.\n- The role of creativity and the potential for AI to enhance creativity rather than replace it.\n- The importance of understanding and fostering values that cannot be measured, such as love, forgiveness, and reconciliation.\n\nOverall, the episode highlights the thoughtful and nuanced discussion around the impact of AI on humanity, the need for ethical considerations, and the importance of human values in shaping the development and deployment of technology."}